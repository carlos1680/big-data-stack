from pyspark.sql import SparkSession
from pyspark.sql.utils import AnalysisException

# ==============================
# ğŸ”§ CONFIGURACIÃ“N DE CONEXIÃ“N
# ==============================
DB_HOST = "mariadb"
DB_PORT = "3306"
DB_NAME = "bigdata_db"
DB_USER = "bigdata_user"
DB_PASS = "bigdata_pass"
TABLE_NAME = "sensores"

# URL JDBC â€” usamos mysql:// + permitMysqlScheme para compatibilidad
url = (
    f"jdbc:mysql://{DB_HOST}:{DB_PORT}/{DB_NAME}"
    "?allowPublicKeyRetrieval=true"
    "&useSSL=false"
    "&permitMysqlScheme"
)

# ==============================
# ğŸš€ INICIAR SESIÃ“N SPARK
# ==============================
spark = (
    SparkSession.builder
    .appName("TestMariaDB_Stable")
    .config("spark.jars", "/opt/spark/jars/mariadb-java-client.jar")
    .getOrCreate()
)

print("ğŸ”Œ Intentando conectar a MariaDB...")
print(f"   â†’ URL: {url}")
print(f"   â†’ Tabla: {TABLE_NAME}")

# ==============================
# ğŸ“¥ LECTURA DESDE MARIADB
# ==============================
try:
    df = (
        spark.read.format("jdbc")
        .option("url", url)
        .option("dbtable", TABLE_NAME)
        .option("user", DB_USER)
        .option("password", DB_PASS)
        .option("driver", "org.mariadb.jdbc.Driver")
        .option("fetchsize", "1000")  # mejora rendimiento para tablas grandes
        .load()
    )

    print("\nâœ… ConexiÃ³n exitosa. Mostrando los primeros registros:\n")
    df.show()
    print("\nğŸ“Š Esquema de la tabla:")
    df.printSchema()
    print(f"\nğŸ“ˆ Total de filas: {df.count()}")

except AnalysisException as e:
    print(f"âš ï¸ Error de anÃ¡lisis Spark: {e}")
except Exception as e:
    print(f"âŒ Error general al conectar o leer datos: {e}")
finally:
    spark.stop()
    print("\nğŸ§¹ SesiÃ³n Spark finalizada correctamente.")
