{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análisis de `payments_gold` (bigdata_db)\n",
        "\n",
        "Este notebook:\n",
        "\n",
        "- Se conecta a **MariaDB** y lee datos desde `bigdata_db.payments_gold`.\n",
        "- Hace **EDA** (calidad, distribuciones, series temporales, cortes por categorías).\n",
        "- Entrena y evalúa **modelos baseline** (scikit-learn) para predecir `is_fraud`.\n",
        "- Genera **insights accionables**.\n",
        "\n",
        "> Recomendación: **no hardcodear credenciales**. Este notebook usa variables de entorno o pide el password por prompt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Si ejecutás esto en un entorno limpio, instalá dependencias (descomentá):\n",
        "!pip install -U pandas numpy matplotlib seaborn sqlalchemy pymysql scikit-learn scipy\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score,\n",
        "    classification_report, confusion_matrix,\n",
        "    RocCurveDisplay, PrecisionRecallDisplay\n",
        ")\n",
        "\n",
        "sns.set_theme(style='whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Conexión a MariaDB\n",
        "\n",
        "Define estas variables de entorno (recomendado):\n",
        "\n",
        "- `MARIADB_HOST` (ej: `172.28.0.10`)\n",
        "- `MARIADB_PORT` (ej: `3306`)\n",
        "- `MARIADB_DB` (ej: `bigdata_db`)\n",
        "- `MARIADB_USER` (ej: `bigdata_user`)\n",
        "- `MARIADB_PASSWORD`\n",
        "\n",
        "Si `MARIADB_PASSWORD` no está seteada, el notebook la pide por prompt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "MARIADB_HOST = os.getenv('MARIADB_HOST', '172.28.0.10')\n",
        "MARIADB_PORT = os.getenv('MARIADB_PORT', '3306')\n",
        "MARIADB_DB   = os.getenv('MARIADB_DB', 'bigdata_db')\n",
        "MARIADB_USER = os.getenv('MARIADB_USER', 'bigdata_user')\n",
        "MARIADB_PASSWORD = os.getenv('MARIADB_PASSWORD')\n",
        "\n",
        "if not MARIADB_PASSWORD:\n",
        "    MARIADB_PASSWORD = getpass('MariaDB password: ')\n",
        "\n",
        "# MariaDB suele funcionar perfecto con dialecto mysql + driver PyMySQL desde Python\n",
        "engine = create_engine(\n",
        "    f\"mysql+pymysql://{MARIADB_USER}:{MARIADB_PASSWORD}@{MARIADB_HOST}:{MARIADB_PORT}/{MARIADB_DB}\",\n",
        "    pool_pre_ping=True,\n",
        ")\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    version = conn.execute(text('SELECT VERSION()')).scalar()\n",
        "\n",
        "print('✅ Conectado. VERSION():', version)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Cargar datos desde `payments_gold`\n",
        "\n",
        "Tips:\n",
        "- Si la tabla es grande, empezá con un `LIMIT`.\n",
        "- Para modelos/EDA robustos, podés traer una ventana temporal (ej. últimos N días).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TABLE = 'payments_gold'\n",
        "\n",
        "# Ajustá esto según tamaño\n",
        "LIMIT = int(os.getenv('PAYMENTS_GOLD_LIMIT', '200000'))  # 200k por defecto\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    total_rows = conn.execute(text(f\"SELECT COUNT(*) FROM {TABLE}\")).scalar()\n",
        "\n",
        "print('Total filas en la tabla:', total_rows)\n",
        "\n",
        "query = f\"SELECT * FROM {TABLE} ORDER BY event_ts DESC LIMIT {LIMIT}\"\n",
        "\n",
        "df = pd.read_sql(query, engine)\n",
        "print('Filas cargadas:', len(df))\n",
        "print('Columnas:', list(df.columns))\n",
        "\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Normalización rápida de tipos\n",
        "\n",
        "Esperado (por tu pipeline Silver→Gold):\n",
        "- `event_ts`: timestamp\n",
        "- `amount`: numérico\n",
        "- `is_fraud`: booleano (a veces viene como 0/1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# event_ts\n",
        "if 'event_ts' in df.columns:\n",
        "    df['event_ts'] = pd.to_datetime(df['event_ts'], errors='coerce', utc=True)\n",
        "\n",
        "# amount\n",
        "if 'amount' in df.columns:\n",
        "    df['amount'] = pd.to_numeric(df['amount'], errors='coerce')\n",
        "\n",
        "# is_fraud\n",
        "if 'is_fraud' in df.columns:\n",
        "    # Convertir bytes a int si es necesario\n",
        "    if df['is_fraud'].dtype == object and all(isinstance(x, bytes) for x in df['is_fraud']):\n",
        "        df['is_fraud'] = df['is_fraud'].apply(lambda x: int.from_bytes(x, 'big'))\n",
        "    \n",
        "    # Convertir a booleano\n",
        "    df['is_fraud'] = df['is_fraud'].astype('float').fillna(0).astype(int).astype(bool)\n",
        "\n",
        "# tx_count_window\n",
        "if 'tx_count_window' in df.columns:\n",
        "    df['tx_count_window'] = pd.to_numeric(df['tx_count_window'], errors='coerce')\n",
        "\n",
        "# risk_score\n",
        "if 'risk_score' in df.columns:\n",
        "    df['risk_score'] = pd.to_numeric(df['risk_score'], errors='coerce')\n",
        "\n",
        "(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Calidad de datos (missing, duplicados, rangos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Missingness\n",
        "missing = (df.isna().mean().sort_values(ascending=False) * 100).to_frame('missing_%')\n",
        "missing.head(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Duplicados por event_id (si existe)\n",
        "if 'event_id' in df.columns:\n",
        "    dup = df['event_id'].duplicated().mean() * 100\n",
        "    print(f\"Duplicados event_id: {dup:.3f}%\")\n",
        "else:\n",
        "    print('No existe event_id en el dataset cargado')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rangos básicos\n",
        "cols_numeric = [c for c in ['amount','tx_count_window','risk_score'] if c in df.columns]\n",
        "if cols_numeric:\n",
        "    display(df[cols_numeric].describe(percentiles=[.01,.05,.5,.95,.99]).T)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Distribuciones principales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'amount' in df.columns:\n",
        "    sns.histplot(df['amount'].dropna(), bins=50)\n",
        "    plt.title('Distribución de amount')\n",
        "    plt.show()\n",
        "\n",
        "if 'tx_count_window' in df.columns:\n",
        "    sns.histplot(df['tx_count_window'].dropna(), bins=50)\n",
        "    plt.title('Distribución de tx_count_window')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Análisis temporal (volumen + tasa de fraude)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'event_ts' in df.columns:\n",
        "    df_time = df.dropna(subset=['event_ts']).copy()\n",
        "    df_time['date'] = df_time['event_ts'].dt.floor('D')\n",
        "\n",
        "    daily = df_time.groupby('date').agg(\n",
        "        n=('event_ts','size'),\n",
        "        fraud_rate=('is_fraud', 'mean') if 'is_fraud' in df_time.columns else ('event_ts','size')\n",
        "    ).reset_index()\n",
        "\n",
        "    ax = daily.plot(x='date', y='n', kind='line', title='Volumen diario')\n",
        "    ax.set_xlabel('date'); ax.set_ylabel('n')\n",
        "    plt.show()\n",
        "\n",
        "    if 'is_fraud' in df_time.columns:\n",
        "        ax = daily.plot(x='date', y='fraud_rate', kind='line', title='Tasa de fraude diaria')\n",
        "        ax.set_xlabel('date'); ax.set_ylabel('fraud_rate')\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Cortes por categorías (top N)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def top_rate(df_in, group_col, target_col='is_fraud', min_count=50, top_n=20):\n",
        "    if group_col not in df_in.columns or target_col not in df_in.columns:\n",
        "        return None\n",
        "    g = df_in.groupby(group_col).agg(\n",
        "        n=(target_col, 'size'),\n",
        "        fraud_rate=(target_col, 'mean'),\n",
        "        amount_mean=('amount','mean') if 'amount' in df_in.columns else (target_col, 'size')\n",
        "    ).reset_index()\n",
        "    g = g[g['n'] >= min_count].sort_values('fraud_rate', ascending=False).head(top_n)\n",
        "    return g\n",
        "\n",
        "for col in ['merchant_id','payment_method','currency','device_id','ip_address','fraud_reason']:\n",
        "    if col in df.columns and 'is_fraud' in df.columns:\n",
        "        t = top_rate(df, col, min_count=100, top_n=15)\n",
        "        if t is not None and len(t):\n",
        "            display(t)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Modelo: baselines para predecir `is_fraud`\n",
        "\n",
        "Este bloque:\n",
        "- arma features numéricas + categóricas\n",
        "- hace split temporal si existe `event_ts`, para evitar leakage\n",
        "- entrena 3 modelos: `Dummy`, `LogisticRegression`, `RandomForest`\n",
        "- reporta ROC-AUC y PR-AUC (más útil en clases desbalanceadas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Elegimos target\n",
        "if 'is_fraud' not in df.columns:\n",
        "    raise RuntimeError('La tabla no tiene columna is_fraud. No puedo entrenar un modelo supervisado.')\n",
        "\n",
        "# Features candidatas (ajustá según tu tabla real)\n",
        "feature_candidates = [\n",
        "    'amount', 'tx_count_window', 'risk_score', 'hour', 'dow',\n",
        "    'merchant_id', 'payment_method', 'currency', 'device_id', 'ip_address', 'status', 'user_id'\n",
        "]\n",
        "features = [c for c in feature_candidates if c in df.columns]\n",
        "print('Features usadas:', features)\n",
        "\n",
        "data = df.dropna(subset=['is_fraud']).copy()\n",
        "\n",
        "# si no existen hour/dow, los calculamos desde event_ts\n",
        "if 'event_ts' in data.columns:\n",
        "    if 'hour' not in data.columns:\n",
        "        data['hour'] = pd.to_datetime(data['event_ts'], utc=True, errors='coerce').dt.hour\n",
        "    if 'dow' not in data.columns:\n",
        "        data['dow'] = pd.to_datetime(data['event_ts'], utc=True, errors='coerce').dt.dayofweek\n",
        "\n",
        "X = data[features]\n",
        "y = data['is_fraud'].astype(int)\n",
        "\n",
        "# Split temporal (recomendado) si hay timestamp\n",
        "if 'event_ts' in data.columns:\n",
        "    order = data['event_ts'].astype('int64')\n",
        "    idx = np.argsort(order.values)\n",
        "    cutoff = int(0.8 * len(idx))\n",
        "    train_idx, test_idx = idx[:cutoff], idx[cutoff:]\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "    print('Split temporal: train=', len(train_idx), 'test=', len(test_idx))\n",
        "else:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    print('Split random: train=', len(X_train), 'test=', len(X_test))\n",
        "\n",
        "num_cols = [c for c in X_train.columns if X_train[c].dtype != 'object']\n",
        "cat_cols = [c for c in X_train.columns if X_train[c].dtype == 'object']\n",
        "print('Num:', num_cols)\n",
        "print('Cat:', cat_cols)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler  # Importar StandardScaler\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler()),  # Escalar las características numéricas\n",
        "        ]), num_cols),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('ohe', OneHotEncoder(handle_unknown='ignore')),\n",
        "        ]), cat_cols),\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "models = {\n",
        "    'dummy_most_frequent': DummyClassifier(strategy='most_frequent'),\n",
        "    'logreg': LogisticRegression(max_iter=1000, class_weight='balanced', n_jobs=None, solver='liblinear'),  # Aumentar max_iter y cambiar solver\n",
        "    'rf': RandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=None,\n",
        "        min_samples_leaf=5,\n",
        "        class_weight='balanced_subsample',\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, clf in models.items():\n",
        "    pipe = Pipeline(steps=[('prep', preprocess), ('clf', clf)])\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    # scores/probas\n",
        "    if hasattr(pipe.named_steps['clf'], 'predict_proba'):\n",
        "        proba = pipe.predict_proba(X_test)[:, 1]\n",
        "    else:\n",
        "        # fallback (dummy)\n",
        "        proba = pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    roc = roc_auc_score(y_test, proba)\n",
        "    ap = average_precision_score(y_test, proba)\n",
        "    results.append((name, roc, ap))\n",
        "\n",
        "    print('===', name, '===')\n",
        "    print('ROC-AUC:', roc)\n",
        "    print('PR-AUC :', ap)\n",
        "\n",
        "    RocCurveDisplay.from_predictions(y_test, proba)\n",
        "    plt.title(f'ROC - {name}')\n",
        "    plt.show()\n",
        "\n",
        "    PrecisionRecallDisplay.from_predictions(y_test, proba)\n",
        "    plt.title(f'PR - {name}')\n",
        "    plt.show()\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=['model', 'roc_auc', 'pr_auc']).sort_values('pr_auc', ascending=False)\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Insights rápidos (operativos)\n",
        "\n",
        "- Top merchants por tasa de fraude (con mínimo de eventos)\n",
        "- IPs/Devices con mayor tasa\n",
        "- Relación entre `tx_count_window` y fraude\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'is_fraud' in df.columns:\n",
        "    def show_top(col, min_count=10, top_n=5):\n",
        "        if col not in df.columns:\n",
        "            return\n",
        "        t = (\n",
        "            df.groupby(col)\n",
        "              .agg(n=('is_fraud', 'size'), fraud_rate=('is_fraud', 'mean'))\n",
        "              .reset_index()\n",
        "        )\n",
        "        t = t[t['n'] >= min_count].sort_values('fraud_rate', ascending=False).head(top_n)\n",
        "        if not t.empty:\n",
        "            display(t)\n",
        "        else:\n",
        "            print(f\"No hay suficientes datos para {col} con min_count={min_count}\")\n",
        "\n",
        "    print('Top user_id por tasa de fraude:')\n",
        "    show_top('user_id', min_count=10, top_n=5)\n",
        "\n",
        "    print('Top fraud_reason por tasa de fraude:')\n",
        "    show_top('fraud_reason', min_count=10, top_n=5)\n",
        "\n",
        "if 'tx_count_window' in df.columns and 'is_fraud' in df.columns:\n",
        "    tmp = df[['tx_count_window', 'is_fraud']].dropna().copy()\n",
        "    if not tmp.empty:\n",
        "        tmp['tx_count_window'] = tmp['tx_count_window'].astype(int)\n",
        "        g = tmp.groupby('tx_count_window').agg(n=('is_fraud', 'size'), fraud_rate=('is_fraud', 'mean')).reset_index()\n",
        "        g = g[g['n'] >= 2]\n",
        "        if not g.empty:\n",
        "            sns.lineplot(data=g, x='tx_count_window', y='fraud_rate')\n",
        "            plt.title('Fraud rate vs tx_count_window (bins exactos)')\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No hay suficientes datos para generar la gráfica de fraud rate vs tx_count_window.\")\n",
        "    else:\n",
        "        print(\"No hay suficientes datos en 'tx_count_window' o 'is_fraud'.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
