#!/bin/bash
set -e
export PATH="/home/airflow/.local/bin:$PATH"

LOG_FILE="/opt/airflow/logs/startup.log"
mkdir -p "$(dirname "$LOG_FILE")"

log() {
  echo -e "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

log "ğŸ”§ Verificando entorno de Airflow + Spark..."
log "JAVA_HOME=$JAVA_HOME"
log "SPARK_HOME=$SPARK_HOME"

# Si viene AIRFLOW_DB_CONN desde el compose/.env, reflejarlo en la var oficial
if [ -n "$AIRFLOW_DB_CONN" ] && [ -z "$AIRFLOW__DATABASE__SQL_ALCHEMY_CONN" ]; then
  export AIRFLOW__DATABASE__SQL_ALCHEMY_CONN="$AIRFLOW_DB_CONN"
  log "ğŸ”— AIRFLOW__DATABASE__SQL_ALCHEMY_CONN seteado desde AIRFLOW_DB_CONN"
fi

# Dependencias adicionales opcionales
if [ -x /install-extra.sh ]; then
  log "ğŸ“¦ Ejecutando /install-extra.sh..."
  /install-extra.sh >>"$LOG_FILE" 2>&1 || log "âš ï¸  /install-extra.sh fallÃ³, continuando..."
else
  log "â„¹ï¸  No se encontrÃ³ /install-extra.sh, continuando sin dependencias adicionales."
fi

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§© Esperar MariaDB (host por defecto: 'mariadb')
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MARIADB_HOST=${MARIADB_HOST:-mariadb}
MARIADB_USER=${MARIADB_USER:-bigdata_user}
MARIADB_PASSWORD=${MARIADB_PASSWORD:-bigdata_pass}

if [ -n "$MARIADB_HOST" ]; then
  log "ğŸ§© Esperando que MariaDB ($MARIADB_HOST) estÃ© completamente lista..."
  ATTEMPT=1
  until mysql -h "$MARIADB_HOST" -u"$MARIADB_USER" -p"$MARIADB_PASSWORD" -e "SELECT 1;" >/dev/null 2>&1; do
    log "â³ Intento $ATTEMPT: MariaDB aÃºn no responde, reintentando en 5s..."
    sleep 5
    ((ATTEMPT++))
  done
  log "âœ… MariaDB lista despuÃ©s de $ATTEMPT intentos, continuando con Airflow..."
fi

case "$1" in
  webserver)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ—„ï¸ InicializaciÃ³n / migraciÃ³n de DB Airflow
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    log "â³ Comprobando estado de migraciones de Airflow..."
    if ! airflow db check-migrations >/dev/null 2>&1; then
      log "ğŸ§  Ejecutando 'airflow db init' (primera vez)..."
      airflow db init >>"$LOG_FILE" 2>&1 || log "âš ï¸  Error en 'airflow db init', continuando..."
    fi

    log "â¬†ï¸ Ejecutando 'airflow db upgrade'..."
    airflow db upgrade >>"$LOG_FILE" 2>&1 || log "âš ï¸  Error en 'airflow db upgrade', continuando..."

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ‘¤ Usuario admin idempotente
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    log "ğŸ‘¤ Creando usuario admin (si no existe)..."
    airflow users create \
      --username "${AIRFLOW_ADMIN_USER:-admin}" \
      --firstname "${AIRFLOW_ADMIN_FIRSTNAME:-Admin}" \
      --lastname "${AIRFLOW_ADMIN_LASTNAME:-User}" \
      --role Admin \
      --email "${AIRFLOW_ADMIN_EMAIL:-admin@example.com}" \
      --password "${AIRFLOW_ADMIN_PASS:-admin}" >>"$LOG_FILE" 2>&1 || log "â„¹ï¸  Usuario ya existÃ­a."

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ”Œ ConexiÃ³n spark_default idempotente
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    log "ğŸ”Œ Asegurando conexiÃ³n 'spark_default'..."
    if airflow connections get spark_default >/dev/null 2>&1; then
      log "â„¹ï¸  'spark_default' ya existe."
    else
      airflow connections add spark_default \
        --conn-type spark \
        --conn-host "spark://spark-master:7077" \
        --conn-extra "{\"deploy-mode\":\"client\"}" >>"$LOG_FILE" 2>&1 \
        && log "âœ… ConexiÃ³n 'spark_default' creada." \
        || log "âš ï¸  No se pudo crear 'spark_default' (revisa logs)."
    fi

    log "ğŸš€ Iniciando Webserver"
    exec airflow webserver
    ;;

  scheduler)
    log "ğŸ§  Iniciando Scheduler..."
    exec airflow scheduler
    ;;

  worker)
    log "âš™ï¸  Iniciando Celery Worker..."
    exec airflow celery worker
    ;;

  *)
    log "â¡ï¸  Ejecutando comando personalizado: $*"
    exec "$@"
    ;;
esac
