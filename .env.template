# ====
# BIGDATA STACK — .env.template (v2.1)
# Copiá este archivo como ".env" y editá:
#   - los CHANGEME_* (secrets/credenciales)
#   - los valores marcados como "EDITAR" si aplica a tu entorno
# ⚠️ No subas ".env" al repo (agregalo al .gitignore).
# ====

# ====
# 1) RED / DOCKER NETWORK (EDITAR solo si cambiás tu red interna)
# ====
NETWORK_NAME=bigdata_net
SUBNET=172.28.0.0/16

# ====
# 2) MARIADB (CREDENCIALES = SECRET)
# ====
MARIADB_VERSION=11.4

# SECRET: password root de MariaDB
MARIADB_ROOT_PASSWORD=CHANGEME_MARIADB_ROOT_PASSWORD

# DB por defecto para apps
MARIADB_DATABASE=bigdata_db

# Usuario app (EDITAR si querés otro)
MARIADB_USER=bigdata_user

# SECRET: password del usuario app
MARIADB_PASSWORD=CHANGEME_MARIADB_PASSWORD

# Networking interno
MARIADB_IP=172.28.0.10
MARIADB_PORT=3306

# ====
# 3) MINIO (CREDENCIALES = SECRET)
# ====
MINIO_VERSION=latest

# SECRET: credenciales root de MinIO
MINIO_ROOT_USER=CHANGEME_MINIO_ROOT_USER
MINIO_ROOT_PASSWORD=CHANGEME_MINIO_ROOT_PASSWORD

# Bucket por defecto
MINIO_BUCKET=data

# Puertos (host)
MINIO_PORT=9000
MINIO_CONSOLE_PORT=9001

# Networking interno
MINIO_IP=172.28.0.11

# Para scripts/clients (Spark / Python) dentro de docker
MINIO_ENDPOINT=http://minio:9000

# S3 creds (normalmente mismas que ROOT_* en tu setup)
MINIO_ACCESS_KEY=${MINIO_ROOT_USER}
MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD}

# Prefijo default para datos
MINIO_PREFIX=raw/kafka/test_topic

# ====
# 4) ADMINER (sin secrets)
# ====
ADMINER_IP=172.28.0.12

# ====
# 5) SPARK (sin secrets)
# ====
SPARK_VERSION=3.5.0

SPARK_MASTER_IP=172.28.0.20
SPARK_WORKER1_IP=172.28.0.21
SPARK_WORKER2_IP=172.28.0.22
SPARK_HISTORY_IP=172.28.0.23

SPARK_MASTER_PORT=7077
SPARK_MASTER_WEBUI_PORT=8080
SPARK_WORKER1_WEBUI_PORT=8081
SPARK_WORKER2_WEBUI_PORT=8082
SPARK_HISTORY_PORT=18080

SPARK_DRIVER_MEMORY=2g
SPARK_EXECUTOR_MEMORY=2g

# ====
# 6) JDBC DRIVERS (sin secrets)
# ====
MARIADB_JDBC_VERSION=3.3.3
MARIADB_JDBC_URL=https://repo1.maven.org/maven2/org/mariadb/jdbc/mariadb-java-client/3.3.3/mariadb-java-client-3.3.3.jar
MYSQL_JDBC_URL=https://repo1.maven.org/maven2/com/mysql/mysql-connector-j/8.4.0/mysql-connector-j-8.4.0.jar

# ====
# 7) SUPERSET (SECRET_KEY + password admin son secrets)
# ====
SUPERSET_VERSION=3.0.2
SUPERSET_PORT=8088
SUPERSET_IP=172.28.0.30

# SECRET: Superset SECRET_KEY (obligatorio y estable)
SUPERSET_SECRET_KEY=CHANGEME_SUPERSET_SECRET_KEY

# Admin Superset (EDITAR si querés)
SUPERSET_ADMIN_USER=admin
SUPERSET_ADMIN_EMAIL=admin@example.com

# SECRET: password del admin de Superset
SUPERSET_ADMIN_PASSWORD=CHANGEME_SUPERSET_ADMIN_PASSWORD

# DB Superset (normalmente en MariaDB)
SUPERSET_DB_HOST=mariadb
SUPERSET_DB_PORT=3306
SUPERSET_DB_USER=${MARIADB_USER}
SUPERSET_DB_PASS=${MARIADB_PASSWORD}
SUPERSET_DB_NAME=superset_db

# OJO: si tu compose no expande vars dentro del .env, hardcodeá usuario/pass/port aquí.
SUPERSET_DATABASE_URI=mysql+pymysql://${MARIADB_USER}:${MARIADB_PASSWORD}@mariadb:3306/superset_db

# ====
# 8) JUPYTERLAB (TOKEN = secret)
# ====
JUPYTER_VERSION=3.5.0
JUPYTER_PORT=8888
JUPYTER_IP=172.28.0.40

# SECRET: token de Jupyter
JUPYTER_TOKEN=CHANGEME_JUPYTER_TOKEN

JUPYTER_SPARK_MASTER=spark://spark-master:7077
JUPYTER_DRIVER_MEMORY=2g
JUPYTER_EXECUTOR_MEMORY=2g

# ====
# 9) AIRFLOW (password admin + keys = secrets)
# ====
AIRFLOW_VERSION=2.10.0

AIRFLOW_INIT_IP=172.28.0.61
AIRFLOW_WEB_IP=172.28.0.62
AIRFLOW_SCHEDULER_IP=172.28.0.63
AIRFLOW_WORKER_IP=172.28.0.64
AIRFLOW_FLOWER_IP=172.28.0.70
REDIS_IP=172.28.0.60

AIRFLOW_PORT=8090
AIRFLOW__WEBSERVER__WEB_SERVER_PORT=8090

# DB Airflow (OJO con expansión ${...} dentro del .env; si te falla, hardcodeá)
AIRFLOW_DB_NAME=airflow_db
AIRFLOW_DB_CONN=mysql+mysqldb://${MARIADB_USER}:${MARIADB_PASSWORD}@mariadb:3306/airflow_db

# Admin Airflow (EDITAR si querés)
AIRFLOW_ADMIN_USER=admin
AIRFLOW_ADMIN_EMAIL=admin@example.com
AIRFLOW_ADMIN_FIRSTNAME=Carlos
AIRFLOW_ADMIN_LASTNAME=Piriz

# SECRET: password del admin de Airflow
AIRFLOW_ADMIN_PASS=CHANGEME_AIRFLOW_ADMIN_PASS

# SECRET: keys (deben ser estables)
AIRFLOW__CORE__FERNET_KEY=CHANGEME_AIRFLOW_FERNET_KEY
AIRFLOW__WEBSERVER__SECRET_KEY=CHANGEME_AIRFLOW_WEBSERVER_SECRET_KEY

# ====
# 10) REDIS / CELERY (sin secrets típicamente)
# ====
REDIS_VERSION=7
REDIS_PORT=6379

AIRFLOW__CORE__EXECUTOR=CeleryExecutor
AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0

# OJO: acá es común que falle si queda como ${MARIADB_PORT}. Usá 3306 literal.
AIRFLOW__CELERY__RESULT_BACKEND=db+mysql://${MARIADB_USER}:${MARIADB_PASSWORD}@mariadb:3306/airflow_db

# ====
# 11) N8N (auth + encryption key son secrets; host/protocol son EDITAR)
# ====
N8N_VERSION=1.122.5
N8N_IP=172.28.0.80
N8N_PORT=5678
N8N_LISTEN_ADDRESS=0.0.0.0

# EDITAR: si usás ngrok/dominio externo, configurá esto
N8N_PROTOCOL=http
N8N_HOST=localhost

# EDITAR: URLs públicas (si no usás túnel, dejá localhost)
N8N_WEBHOOK_URL=http://localhost:5678
WEBHOOK_URL=http://localhost:5678
WEBHOOK_TUNNEL_URL=http://localhost:5678
N8N_EDITOR_BASE_URL=http://localhost:5678

# Opcionales (recomendados)
N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true
N8N_RUNNERS_ENABLED=true
N8N_BASIC_AUTH_ACTIVE=true
N8N_BASIC_AUTH_USER=admin
N8N_BASIC_AUTH_EXCLUDE_ENDPOINTS=/rest/health,/healthz
N8N_DATA_PATH=/home/node/.n8n
DB_SQLITE_POOL_SIZE=5
N8N_GIT_NODE_DISABLE_BARE_REPOS=true
N8N_BLOCK_ENV_ACCESS_IN_NODE=false

# SECRET: password basic auth
N8N_BASIC_AUTH_PASSWORD=CHANGEME_N8N_BASIC_AUTH_PASSWORD

# SECRET: encryption key (debe quedar fija)
N8N_ENCRYPTION_KEY=CHANGEME_N8N_ENCRYPTION_KEY

# ====
# 12) KAFKA / ZOOKEEPER (sin secrets; listeners pueden ser EDITAR)
# ====
KAFKA_VERSION=7.6.0

ZOOKEEPER_IP=172.28.0.50
KAFKA_BROKER_IP=172.28.0.51

ZOOKEEPER_CLIENT_PORT=2181
KAFKA_BROKER_PORT=9092

# Interno Docker
KAFKA_BROKER_ADDR=kafka-broker:9092

# Host (si querés exponer Kafka al host)
KAFKA_BROKER_HOST=localhost

# Config Kafka
KAFKA_BROKER_ID=1
KAFKA_NUM_PARTITIONS=3
KAFKA_DEFAULT_REPLICATION_FACTOR=1

KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092
KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092

# Zookeeper Networking (Faltaban en template)
KAFKA_ZOOKEEPER_HOST=localhost
KAFKA_ZOOKEEPER_PORT=2181

KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
KAFKA_AUTO_CREATE_TOPICS_ENABLE=true

# Opcional JMX
KAFKA_JMX_PORT=9999
KAFKA_JMX_HOST=localhost

# Topic default
KAFKA_TOPIC=test_topic

# ====
# 13) LIB / VERSIONES (sin secrets)
# ====
AIRFLOW_VERSION_LIB=2.10.0
PYSPARK_VERSION_LIB=3.5.0
MARIADB_JDBC_VERSION_LIB=3.3.3
MYSQL_JDBC_VERSION_LIB=8.4.0
MARIADB_JDBC_URL_LIB=https://repo1.maven.org/maven2/org/mariadb/jdbc/mariadb-java-client/3.3.3/mariadb-java-client-3.3.3.jar
MYSQL_JDBC_URL_LIB=https://repo1.maven.org/maven2/com/mysql/mysql-connector-j/8.4.0/mysql-connector-j-8.4.0.jar

# ====
# 14) VARIABLES PARA DAGS Y SCRIPTS (EDITAR si cambiás rutas)
# ====
SPARK_MASTER_URL=spark://spark-master:7077
SPARK_SUBMIT_PATH=/opt/spark/bin/spark-submit
SPARK_CONTAINER_NAME=spark-master
SPARK_EXAMPLES_JAR=/opt/spark/examples/jars/spark-examples_2.12-3.5.0.jar
SPARK_PI_CLASS=org.apache.spark.examples.SparkPi
SPARK_PI_ITERATIONS=100

DOCKER_BIN=docker

# MariaDB desde scripts PySpark
DB_HOST=mariadb
DB_PORT=3306
DB_NAME=bigdata_db
DB_USER=${MARIADB_USER}
DB_PASS=${MARIADB_PASSWORD}
DB_TABLE=sensores
JDBC_JAR=/opt/spark/jars/mariadb-java-client.jar

SPARK_APP_NAME=TestMariaDB_Stable
SPARK_SESSION_TZ=UTC
JDBC_FETCHSIZE=1000

# Paths scripts (ajustá si usás otros nombres)
SPARK_APP_PATH=/opt/spark/app/test_mariadb.py
SPARK_APP_PATH_KAFKA_CSV=/opt/spark/app/spark_kafka_to_csv.py

# Output CSV (host volume)
CSV_OUTPUT_PATH=/opt/shared/kafka_data.csv


MLFOW_PORT=5000
MLFLOW_IP=172.28.0.90
MLFLOW_S3_ENDPOINT_URL=http://minio:9000