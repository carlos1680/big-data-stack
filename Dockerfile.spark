ARG SPARK_VERSION

FROM apache/spark:${SPARK_VERSION}

ARG MARIADB_JDBC_URL_LIB

USER root

# 1. Instalar dependencias del sistema
RUN apt-get update && apt-get install -y --no-install-recommends \
    wget curl bash && \
    rm -rf /var/lib/apt/lists/*

# 2. Instalar paquetes Python
RUN pip3 install --no-cache-dir python-dotenv kafka-python boto3 pyarrow pandas yfinance lxml html5lib

# 3. Preparar carpetas
RUN chmod 777 /tmp && \
    mkdir -p /opt/spark/conf /opt/spark/app /tmp/spark-events && \
    chmod -R 777 /tmp/spark-events

# ==== ZONA DE LIBRERÍAS (BAKED IN) ====

# A. Driver MariaDB
RUN curl -fL -o /opt/spark/jars/mariadb-java-client.jar "${MARIADB_JDBC_URL_LIB}"

# B. CIRUGÍA DE HADOOP (Upgrade a 3.4.0)
# Borramos los "runtime" viejos que esconden la versión antigua
RUN rm -f /opt/spark/jars/hadoop-client-api-*.jar \
          /opt/spark/jars/hadoop-client-runtime-*.jar

# Descargamos el set completo de Hadoop 3.4.0 (Runtime + API + AWS)
# IMPORTANTE: hadoop-client-runtime-3.4.0 contiene hadoop-common actualizado.
RUN curl -fL -o /opt/spark/jars/hadoop-client-api-3.4.0.jar "https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.4.0/hadoop-client-api-3.4.0.jar" && \
    curl -fL -o /opt/spark/jars/hadoop-client-runtime-3.4.0.jar "https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.4.0/hadoop-client-runtime-3.4.0.jar" && \
    curl -fL -o /opt/spark/jars/hadoop-aws-3.4.0.jar "https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.4.0/hadoop-aws-3.4.0.jar"

# C. AWS Bundles (V1 y V2)
# El V1 es para compatibilidad legacy, el V2 es obligatorio para Hadoop 3.4.0
RUN curl -fL -o /opt/spark/jars/aws-java-sdk-bundle-1.12.777.jar "https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.777/aws-java-sdk-bundle-1.12.777.jar" && \
    curl -fL -o /opt/spark/jars/bundle-2.23.19.jar "https://repo1.maven.org/maven2/software/amazon/awssdk/bundle/2.23.19/bundle-2.23.19.jar"

# ======================================

USER 185
ENV PATH="/opt/spark/bin:/opt/spark/sbin:${PATH}"
ENTRYPOINT ["bash", "-lc", "set -euo pipefail; case \"${SPARK_MODE:-master}\" in master) export SPARK_NO_DAEMONIZE=1; /opt/spark/sbin/start-master.sh ;; worker) export SPARK_NO_DAEMONIZE=1; /opt/spark/sbin/start-worker.sh ${SPARK_MASTER} ;; history) export SPARK_NO_DAEMONIZE=1; /opt/spark/sbin/start-history-server.sh ;; esac"]