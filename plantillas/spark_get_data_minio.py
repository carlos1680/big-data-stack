from pyspark.sql import SparkSession
import os

# Configuraci√≥n desde variables de entorno (Consistente con script de carga)
MINIO_ENDPOINT = os.getenv("MINIO_ENDPOINT", "http://minio:9000")
MINIO_ACCESS_KEY = os.getenv("MINIO_ACCESS_KEY", "admin")
MINIO_SECRET_KEY = os.getenv("MINIO_SECRET_KEY", "admin123")
MINIO_BUCKET = os.getenv("MINIO_BUCKET", "data")
MINIO_PREFIX = os.getenv("MINIO_PREFIX", "raw/kafka/test_topic")

# Construcci√≥n de la ruta S3A
input_path = f"s3a://{MINIO_BUCKET}/{MINIO_PREFIX}/"

# Inicializar Spark con la misma configuraci√≥n del script de escritura
spark = (
    SparkSession.builder
    .appName("Get_Data_from_MinIO")
    .config("spark.hadoop.fs.s3a.endpoint", MINIO_ENDPOINT)
    .config("spark.hadoop.fs.s3a.access.key", MINIO_ACCESS_KEY)
    .config("spark.hadoop.fs.s3a.secret.key", MINIO_SECRET_KEY)
    .config("spark.hadoop.fs.s3a.path.style.access", "true")
    .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem")
    .config("spark.hadoop.fs.s3a.aws.credentials.provider", "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider")
    .config("spark.hadoop.fs.s3a.connection.ssl.enabled", "false")
    .getOrCreate()
)

print("\n" + "=" * 90)
print(f"üì• Leyendo datos desde: {input_path}")
print("=" * 90)

try:
    # Leer el dataset Parquet usando Spark nativo
    df = spark.read.parquet(input_path)

    # Mostrar Schema
    print("\nüß± Schema del Dataset:")
    df.printSchema()

    # Mostrar Preview (equivalente a tu PREVIEW_ROWS)
    n_rows = int(os.getenv("PREVIEW_ROWS", "20"))
    print(f"\nüìä Preview de las primeras {n_rows} filas:")
    df.show(n_rows, truncate=False)

    # Conteo total para verificaci√≥n
    total_count = df.count()
    print(f"\n‚úÖ Total de registros encontrados: {total_count}")

except Exception as e:
    print(f"‚ùå Error al leer los datos: {e}")
    # En caso de que el prefijo no exista o est√© vac√≠o
    print("Aseg√∫rate de que la ruta existe y contiene archivos .parquet")

finally:
    print("=" * 90 + "\n")
    spark.stop()